{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "implement_RNN.ipynb",
      "provenance": [],
      "collapsed_sections": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "import torch\n",
        "import torch.nn as nn\n",
        "import torch.nn.functional as F\n",
        "from torch.utils.data import Dataset"
      ],
      "metadata": {
        "id": "lppXr17quKfs"
      },
      "execution_count": 1,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "from torch.utils.data import DataLoader"
      ],
      "metadata": {
        "id": "xnLEJn1XxvcN"
      },
      "execution_count": 2,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "import numpy as np"
      ],
      "metadata": {
        "id": "zF59OKOguKOV"
      },
      "execution_count": 3,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "text = ['hey how are you', 'good i am fine', 'have a nice day']"
      ],
      "metadata": {
        "id": "3tNxwHnulXXR"
      },
      "execution_count": 4,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "chars = set(''.join(text))"
      ],
      "metadata": {
        "id": "nbSu68wBlXTG"
      },
      "execution_count": 5,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int2char = dict(enumerate(chars))"
      ],
      "metadata": {
        "id": "oNEfc_FblXKO"
      },
      "execution_count": 6,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "int2char"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "sIFaz5Vll2Bu",
        "outputId": "0ce83fa2-8c82-4f38-bb4c-f3b84bd93df2"
      },
      "execution_count": 7,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{0: 'r',\n",
              " 1: 'g',\n",
              " 2: 'i',\n",
              " 3: 'y',\n",
              " 4: 'o',\n",
              " 5: ' ',\n",
              " 6: 'h',\n",
              " 7: 'e',\n",
              " 8: 'f',\n",
              " 9: 'n',\n",
              " 10: 'w',\n",
              " 11: 'a',\n",
              " 12: 'u',\n",
              " 13: 'v',\n",
              " 14: 'm',\n",
              " 15: 'c',\n",
              " 16: 'd'}"
            ]
          },
          "metadata": {},
          "execution_count": 7
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "char2int = {v:k for k,v in int2char.items()}"
      ],
      "metadata": {
        "id": "28ts943WlW9P"
      },
      "execution_count": 8,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "char2int"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "b39Fex-slW6I",
        "outputId": "b4f8d195-8107-4a3e-c4ec-3614eeb4f55d"
      },
      "execution_count": 9,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "{' ': 5,\n",
              " 'a': 11,\n",
              " 'c': 15,\n",
              " 'd': 16,\n",
              " 'e': 7,\n",
              " 'f': 8,\n",
              " 'g': 1,\n",
              " 'h': 6,\n",
              " 'i': 2,\n",
              " 'm': 14,\n",
              " 'n': 9,\n",
              " 'o': 4,\n",
              " 'r': 0,\n",
              " 'u': 12,\n",
              " 'v': 13,\n",
              " 'w': 10,\n",
              " 'y': 3}"
            ]
          },
          "metadata": {},
          "execution_count": 9
        }
      ]
    },
    {
      "cell_type": "markdown",
      "source": [
        "Maxlen"
      ],
      "metadata": {
        "id": "5AZ5l658mYkn"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen = len(max(text, key=len))"
      ],
      "metadata": {
        "id": "VPKm4rwvlW1X"
      },
      "execution_count": 10,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "maxlen"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "RSynfCwklWvf",
        "outputId": "e267999b-f1e2-4d14-9048-9150d711b6bb"
      },
      "execution_count": 11,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "15"
            ]
          },
          "metadata": {},
          "execution_count": 11
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Da3Wtx-AlWqf"
      },
      "execution_count": 11,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Padding"
      ],
      "metadata": {
        "id": "OEiMvmVQmU58"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(text)):\n",
        "    while len(text[i])<maxlen:\n",
        "        text[i] += \" \""
      ],
      "metadata": {
        "id": "IqoVsaTnmU2V"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "o_apgdFrmUwA"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "input data:\n",
        "* the last input character should be excluded as it does not need to be fetch into the model\n",
        "\n",
        "output data:\n",
        "* one time-step ahead of the input data as this will be the \"correct answer\" "
      ],
      "metadata": {
        "id": "o8QevTTZmUrU"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "y6wfPnqNmUmd"
      },
      "execution_count": 12,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = []\n",
        "target_seq = []\n",
        "\n",
        "for i in range(len(text)):\n",
        "    input_seq.append(text[i][:-1])\n",
        "    target_seq.append(text[i][1:])"
      ],
      "metadata": {
        "id": "ypJkpveFmUis"
      },
      "execution_count": 13,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "print(input_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "GXgN6mmsmTyU",
        "outputId": "9f94a7c9-61bb-4714-899f-ebdb9bb09976"
      },
      "execution_count": 14,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['hey how are yo', 'good i am fine', 'have a nice da']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "print(target_seq)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "HvKwSEkGmTvB",
        "outputId": "e0095819-2cf7-4162-c7d9-9179dc77bbd3"
      },
      "execution_count": 15,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "['ey how are you', 'ood i am fine ', 'ave a nice day']\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "sty2vpD1mTn9"
      },
      "execution_count": 15,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Sentence Embeddings"
      ],
      "metadata": {
        "id": "KMVbbcW3mTjY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "for i in range(len(text)):\n",
        "    input_seq[i] = [char2int[char] for char in input_seq[i]]\n",
        "    target_seq[i] = [char2int[char] for char in target_seq[i]]"
      ],
      "metadata": {
        "id": "OYkTfA56mTgN"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "OYTCgqmTmTce"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "conversion into one hot vectors\n",
        "\n",
        "* dict_size: the number of unique characters in the corpus\n",
        "    * this will determine the one-hot vector size as each character will have an assigned index in that vector\n",
        "* seq_len: the length of the sequences that we are feeding into the model\n",
        "    * standardised the length of our vectors\n",
        "* batch_size: number of sentences that will be feed to the model in one go"
      ],
      "metadata": {
        "id": "EdMuPBuYmTSO"
      }
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "B4yI5evBmTKM"
      },
      "execution_count": 16,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dict_size = len(char2int)\n",
        "seq_len = maxlen-1\n",
        "batch_size = len(text)\n",
        "\n",
        "def one_hot_encoder(sequence, dict_size, seq_len, batch_size):\n",
        "    features = np.zeros((batch_size, seq_len, dict_size), dtype=np.float32)\n",
        "\n",
        "    for i in range(batch_size):\n",
        "        for u in range(seq_len):\n",
        "            features[i, u, sequence[i][u]] = 1\n",
        "    return features"
      ],
      "metadata": {
        "id": "1YW-OJmimTF8"
      },
      "execution_count": 17,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = one_hot_encoder(input_seq, dict_size, seq_len, batch_size)"
      ],
      "metadata": {
        "id": "obGhzEknmTBh"
      },
      "execution_count": 18,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "kChYoWromS9w",
        "outputId": "188cd8d7-0fdc-43d2-850a-ec8f8a600b21"
      },
      "execution_count": 19,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "(3, 14, 17)"
            ]
          },
          "metadata": {},
          "execution_count": 19
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = torch.from_numpy(input_seq)\n",
        "target_seq = torch.Tensor(target_seq)"
      ],
      "metadata": {
        "id": "06s_BK2emS4H"
      },
      "execution_count": 20,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "_d448AsUlWm0"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "to GPU"
      ],
      "metadata": {
        "id": "vNSLv12xsglY"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "is_cuda = torch.cuda.is_available()\n",
        "\n",
        "if is_cuda:\n",
        "    device = torch.device(\"cuda\")\n",
        "    print('GPU is available')\n",
        "else:\n",
        "    device = torch.device(\"cpu\")\n",
        "    print(\"GPU not available\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "vDaBxzg-sggc",
        "outputId": "ac8222d5-d95b-46e0-fd93-6176fda6f196"
      },
      "execution_count": 22,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "GPU not available\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ksAxI63Wsqqx"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "markdown",
      "source": [
        "Model"
      ],
      "metadata": {
        "id": "1XMahb80sgbi"
      }
    },
    {
      "cell_type": "code",
      "source": [
        "class Model(nn.Module):\n",
        "    def __init__(self, input_size, output_size, hidden_dim, n_layers):\n",
        "        super(Model, self).__init__()\n",
        "        self.hidden_dim = hidden_dim\n",
        "        self.n_layers = n_layers\n",
        "\n",
        "        self.rnn = nn.RNN(input_size, hidden_dim, n_layers, batch_first=True)\n",
        "        self.fc = nn.Linear(hidden_dim, output_size)\n",
        "\n",
        "    def forward(self, x):\n",
        "        batch_size = x.size(0)\n",
        "        hidden = self.init_hidden(batch_size)\n",
        "        out, hidden = self.rnn(x, hidden)\n",
        "        out = out.contiguous().view(-1, self.hidden_dim)\n",
        "        out = self.fc(out)\n",
        "\n",
        "        return out, hidden\n",
        "    \n",
        "    def init_hidden(self, batch_size):\n",
        "        hidden = torch.zeros(self.n_layers, batch_size, self.hidden_dim).to(device)\n",
        "        return hidden"
      ],
      "metadata": {
        "id": "bxv5C1PjsgWT"
      },
      "execution_count": 25,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "model = Model(input_size=dict_size, output_size=dict_size, hidden_dim=12, n_layers=1)\n",
        "model = model.to(device)"
      ],
      "metadata": {
        "id": "2KC2WODklWio"
      },
      "execution_count": 26,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "epochs = 100\n",
        "lr = 0.01\n",
        "\n",
        "criterion = nn.CrossEntropyLoss()\n",
        "optimizer = torch.optim.Adam(model.parameters(), lr)"
      ],
      "metadata": {
        "id": "pz0HHmSitJjl"
      },
      "execution_count": 27,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "ZW4Nhhi7tJdb"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input_seq = input_seq.to(device)\n",
        "for epoch in range(1, epochs+1):\n",
        "    optimizer.zero_grad()\n",
        "    output, hidden = model(input_seq)\n",
        "    output = output.to(device)\n",
        "    target_seq = target_seq.to(device)\n",
        "    loss = criterion(output, target_seq.view(-1).long())\n",
        "    loss.backward()\n",
        "    optimizer.step()\n",
        "\n",
        "    if epoch%10==0:\n",
        "        print(f\"Epoch {epoch}/{epochs}.............Loss: {loss.item():.4f}\")"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "XXtznzZAtJVk",
        "outputId": "a7f494ae-fe6f-4af0-b1cb-92dda2e66e5a"
      },
      "execution_count": 28,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "Epoch 10/100.............Loss: 2.4802\n",
            "Epoch 20/100.............Loss: 2.0834\n",
            "Epoch 30/100.............Loss: 1.6323\n",
            "Epoch 40/100.............Loss: 1.2232\n",
            "Epoch 50/100.............Loss: 0.8812\n",
            "Epoch 60/100.............Loss: 0.6016\n",
            "Epoch 70/100.............Loss: 0.4078\n",
            "Epoch 80/100.............Loss: 0.2807\n",
            "Epoch 90/100.............Loss: 0.2016\n",
            "Epoch 100/100.............Loss: 0.1550\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "gQC4Wk09lWel"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def predict(model, character):\n",
        "    character = np.array([[char2int[c] for c in character]])\n",
        "    character = one_hot_encoder(character, dict_size, character.shape[1],1)\n",
        "    character = torch.from_numpy(character)\n",
        "    character = character.to(device)\n",
        "\n",
        "    out, hidden = model(character)\n",
        "\n",
        "    prob = F.softmax(out[-1], dim=0).data\n",
        "    char_ind = torch.max(prob, dim=0)[1].item()\n",
        "    return int2char[char_ind], hidden"
      ],
      "metadata": {
        "id": "l3vHPi0IlWa2"
      },
      "execution_count": 29,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def sample(model, out_len, start='hey'):\n",
        "    model.eval()\n",
        "    start = start.lower()\n",
        "    chars = [ch for ch in start]\n",
        "    size = out_len - len(chars)\n",
        "\n",
        "    for i in range(size):\n",
        "        char, h = predict(model, chars)\n",
        "        chars.append(char)\n",
        "\n",
        "    return \"\".join(chars)"
      ],
      "metadata": {
        "id": "dJF3tayHlWQt"
      },
      "execution_count": 30,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "sample(model, 15,'hey')"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "id": "yuB9HhxxlWMh",
        "outputId": "395af30a-e670-4243-f6a9-4ac073c5a1f1"
      },
      "execution_count": 32,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            },
            "text/plain": [
              "'hey how are you'"
            ]
          },
          "metadata": {},
          "execution_count": 32
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "4cqDRBk5lWIt"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "Gc_dJqPIlWEF"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "xoTmxZ-0lV_A"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "CxYJR6p_lV56"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "nA-MTMg6UDV_"
      },
      "outputs": [],
      "source": [
        "class MyDataset(Dataset):\n",
        "    def __init__(self, input, seq_len):\n",
        "        self.input = input\n",
        "        self.seq_len = seq_len\n",
        "    def __getitem__(self, item):\n",
        "        return input[item:item + self.seq_len], input[item + self.seq_len]\n",
        "    def __len__(self):\n",
        "        return len(self.input) - self.seq_len"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "input = np.arange(1,8).reshape(-1, 1)"
      ],
      "metadata": {
        "id": "nq4orUyDuD3P"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "input = torch.tensor(input, dtype=torch.float)"
      ],
      "metadata": {
        "id": "LR4Z7PDUuD7D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "ds = MyDataset(input, 3)"
      ],
      "metadata": {
        "id": "ZBCy_1b_uD_D"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "dl = DataLoader(ds, batch_size=2)\n",
        "for inp, label in dl:\n",
        "    print(inp.numpy())"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "v_QqyVlyuECq",
        "outputId": "df1a827e-e658-469f-85c2-5a39e0fc5be6"
      },
      "execution_count": null,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "[[[1.]\n",
            "  [2.]\n",
            "  [3.]]\n",
            "\n",
            " [[2.]\n",
            "  [3.]\n",
            "  [4.]]]\n",
            "[[[3.]\n",
            "  [4.]\n",
            "  [5.]]\n",
            "\n",
            " [[4.]\n",
            "  [5.]\n",
            "  [6.]]]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "5q6M-hSruEGa"
      },
      "execution_count": null,
      "outputs": []
    }
  ]
}